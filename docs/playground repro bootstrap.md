# playground repro bootstrap

ğŸ›   Bootstrap reproduction model  
  
ğŸ‘‰ Check documentation https://kafka-docker-playground.io/#/reusables?id=%f0%9f%9b%a0-bootstrap-reproduction-model

## Usage

```bash
playground repro bootstrap [OPTIONS] [ARGUMENTS...]
```

## Options

#### *--tag TAG*

ğŸ¯ Confluent Platform (CP) version to use  
  
Must be greater or equal to 5.0.0

#### *--connector-tag CONNECTOR_TAG*

ğŸ”— Connector version to use  
  
By default, for each connector, the latest available version on Confluent Hub is used  
  
ğŸ“ Tip: set to " " in order to select the version dynamically

| Attributes      | &nbsp;
|-----------------|-------------
| Conflicts With: | *--connector-zip*

#### *--connector-zip CONNECTOR_ZIP*

ğŸ¤ Connector zip to use  
  
â• It must be absolute full path  
  
ğŸ“ Tip: use \<tab\> completion to trigger fzf completion   
        use playground config folder_zip_or_jar \<folder1\> \<folder2\>... (default is home folder and current folder is always included) to configure where to search the files

| Attributes      | &nbsp;
|-----------------|-------------
| Conflicts With: | *--connector-tag*

#### *--connector-jar CONNECTOR_JAR*

â™¨ï¸ Connector jar to use  
  
â• It must be absolute full path  
  
ğŸ“ Tip: use \<tab\> completion to trigger fzf completion   
        use playground config folder_zip_or_jar \<folder1\> \<folder2\>... (default is home folder and current folder is always included) to configure where to search the files

#### *--enable-ksqldb*

ğŸš€ Enable ksqlDB  
  
By default, ksqldb-server and ksqldb-cli containers are not started for every test

#### *--enable-rest-proxy*

ğŸ§² Enable Rest Proxy  
  
By default, rest-proxy container is not started for every test

#### *--enable-control-center*

ğŸ’  Enable Control Center  
  
By default, control-center container is not started for every test  
  
Control Center is reachable at http://127.0.0.1:9021

#### *--enable-conduktor*

ğŸº Enable Conduktor Platform  
  
By default, Conduktor Platform container is not started for every test  
  
Conduktor is reachable at http://127.0.0.1:8080/console (admin/admin)

#### *--enable-multiple-brokers*

3ï¸âƒ£ Enable multiple brokers  
  
By default, there is only one broker node enabled

#### *--enable-multiple-connect-workers*

ğŸ¥‰ Enable multiple connect node  
  
By default, there is only one connect node enabled  
  
It only works when plaintext environment is used

#### *--enable-jmx-grafana*

Enable Grafana, Prometheus and Pyroscope  
  
ğŸ“Š Grafana is reachable at http://127.0.0.1:3000 (login/password is admin/password)  
  
ğŸ›¡ï¸ Prometheus is reachable at http://127.0.0.1:9090  
  
ğŸ“› Pyroscope is reachable at http://127.0.0.1:4040

#### *--enable-kcat*

ğŸˆâ€â¬› Enable kcat  
  
You can use it with:  
  
$ docker exec kcat kcat -b broker:9092 -L

#### *--enable-sql-datagen*

ğŸŒªï¸ Enable SQL Datagen injection  
  
This only works for Oracle, MySql, Postgres and Microsoft Sql Server source connector examples with JDBC and Debezium

#### *--cluster-type CLUSTER-TYPE*

ğŸ”‹ The cluster type: basic, standard or dedicated. Default is basic  
  
ğŸ“ Tip: you can also use CLUSTER_TYPE environment variable

| Attributes      | &nbsp;
|-----------------|-------------
| Allowed Values: | basic, standard, dedicated

#### *--cluster-region CLUSTER-REGION*

ğŸ—º The Cloud region.   
  
ğŸ“ Tip: you can also use CLUSTER_REGION environment variable

#### *--cluster-environment CLUSTER-ENVIRONMENT*

ğŸŒ The environment id where want your new cluster (example: env-xxxxx)  
  
â„¹ï¸ Optional, if not set, new environment will be created  
  
ğŸ“ Tip: you can also use ENVIRONMENT environment variable

#### *--cluster-name CLUSTER-NAME*

ğŸ° The cluster name.   
  
â£ï¸ Only required if you want to use your own existing cluster  
  
ğŸ“ Tip: you can also use CLUSTER_NAME environment variable

#### *--cluster-creds CLUSTER-CREDS*

ğŸ”’ The Kafka api key and secret to use, it should be separated with semi-colon (example: \<API_KEY\>:\<API_KEY_SECRET\>)  
  
â£ï¸ Only required if you want to use your own existing cluster  
  
ğŸ“ Tip: you can also use CLUSTER_CREDS environment variable

#### *--cluster-schema-registry-creds CLUSTER-SCHEMA-REGISTRY-CREDS*

ğŸ”’ The Schema Registry api key and secret to use, it should be separated with semi-colon (example: \<SR_API_KEY\>:\<SR_API_KEY_SECRET\>)  
  
â„¹ï¸ Optional, if not set, new credentials will be created  
  
â£ï¸ Only required if you want to use your own existing cluster  
  
ğŸ“ Tip: you can also use SCHEMA_REGISTRY_CREDS environment variable

#### *--file, -f FILE*

ğŸ”– Example file to use as basis, if not set, currently running example is used  
  
â• It must be absolute full path  
  
ğŸ“ Tip: use \<tab\> completion to trigger fzf completion

#### *--description, -d DESCRIPTION*

ğŸ’­ Description for the reproduction model

| Attributes      | &nbsp;
|-----------------|-------------
| Required:       | âœ“ Yes

#### *--custom-smt*

âš™ï¸ Add a custom SMT (which is a no-op)

#### *--pipeline SINK_FILE*

ğŸ”– Sink example file to use for creating a pipeline. multiple --pipeline flags can be used to create a pipeline with multiple sinks.  
  
â• It must be absolute full path.   
  
ğŸ“ Tip: use \<tab\> completion to trigger fzf completion

| Attributes      | &nbsp;
|-----------------|-------------
| Repeatable:     |  âœ“ Yes
| Conflicts With: | *--producer*

## Examples

```bash
playground repro bootstrap -f hdfs2<tab> -d "simple test"
```

```bash
playground repro bootstrap -f /full/path/hdfs2-sink.sh -d "testing with avro producer" --producer avro --producer-schema-value myschema<tab>
```

```bash
playground repro bootstrap -f hdfs2<tab> -d "testing with 2 protobuf producers" --producer protobuf --nb-producers 2
```

```bash
playground repro bootstrap -f hdfs2<tab> -d "testing custom smt" --custom-smt
```

```bash
playground repro bootstrap -f debeziumpostgres<tab> -d "create pipeline" --pipeline jdbcsink<tab>
```


